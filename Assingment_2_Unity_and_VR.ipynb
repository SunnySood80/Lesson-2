{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment 2: Environment Scanning and Object Detection\n",
        "\n",
        "### **1. Environment Scanning Using Scanniverse App**\n",
        "- Utilize the **Scanniverse app** with specific output settings listed down below to scan an environment. Include a demonstration of the scanned area in your submission.\n",
        "    - **Note**: The Scanniverse app **only** works on iOS devices. If you have an Android or a different OS, please search for an alternative 3D scanning app that allows you to export 3D models. For those needing to scan an environment or unsure what to scan, you may find a **3D setting online** suitable for Unity.\n",
        "\n",
        "### **2. Dataset Acquisition**\n",
        "- Visit **Roboflow** to find a dataset for the object detection task. This dataset should be relevant to the type of objects you intend to detect within your scanned or selected environment.\n",
        "\n",
        "### **3. Train Your Own Model**\n",
        "- Using the dataset acquired from Roboflow, train your own model to recognize and detect objects within the environment.\n",
        "\n",
        "### **4. Detection and Results Presentation**\n",
        "- Deploy your trained model to detect objects in the scanned environment. Show the results of the detected labels.\n",
        "    - Screenshots or video demonstrations are encouraged to effectively showcase the detection results.\n",
        "\n",
        "**Submission Guidelines**:\n",
        "Ensure your submission includes:\n",
        "- A brief description of the scanned environment or the 3D setting selected.\n",
        "- Details on the dataset from Roboflow, including the type of objects and the number of images.\n",
        "- Information on the model training process, provide details on the model architecture, training parameters, and any pre-processing steps involved.\n",
        "- Visual evidence of the detection results, clearly showing the effectiveness of your model. For this, take a screen recording of your unity scene running as you walk through it detecting objects.\n",
        "\n",
        "**Evaluation Criteria**:\n",
        "Submissions will be evaluated based on:\n",
        "- The complexity and relevance of the chosen environment.\n",
        "- The appropriateness and quality of the dataset used for training.\n",
        "- The accuracy and efficiency of the trained model in detecting objects.\n",
        "- The clarity and detail of the presentation of your results.\n"
      ],
      "metadata": {
        "id": "_D4Sf9ecTkbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some examples:\n",
        "\n",
        "- **Historical Landmarks**: Scan a local historical site or monument. Detect architectural features, informational plaques, or unique sculptures.\n",
        "- **Public Parks**: Capture the diverse environment of a public park. You could focus on detecting different types of vegetation, playground equipment, or park benches.\n",
        "- **Personal Workspace**: Scan your personal workspace or studio. Detect items like computer setups, art supplies, or books.\n",
        "- **Urban Street Scenes**: Choose a vibrant street scene for scanning. Detect vehicles, street signs, storefronts, or pedestrians (ensure privacy by avoiding clear faces).\n",
        "- **Home Interior**: Scan an interior space in your home, like a living room or kitchen. Detect furniture, appliances, and decor items.\n",
        "- **Educational Institutions**: Scan parts of an educational institution, like a classroom, library, or laboratory. Detect desks, books, lab equipment, or art installations.\n"
      ],
      "metadata": {
        "id": "fAQmCuqeYSsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scanning environment and importing 3D scenes"
      ],
      "metadata": {
        "id": "fEpmfLUZU85W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Download the Scaniverse app on any iOS hand held device.\n",
        "2. Click on the new scan plus button below.\n",
        "3. Select large object / area as the scan size.\n",
        "4. Scan your environment, follow the instructions.\n",
        "   - **Note**: For best results in getting an accurate scan, slow down, get close up, and don't be afraid to rescan if your desired output is not ideal.\n",
        "5. **IMPORTANT**: select your processing mode as **Detail** for the best quality in Unity.\n",
        "6. Click **save** > **share** > **Export model**, choose **OBJ** for ease, and email it to yourself.\n",
        "7. Import into Unity"
      ],
      "metadata": {
        "id": "mxJSzDIhVGNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If importing a scene from Scaniverse or online, Unity supports a variety of 3D model formats, with the most common being **FBX**, **DAE** (Collada), **GLTF**, **OBJ**, and **3DS**. For optimal performance and compatibility, your 3D models should ideally consist of a 3D mesh and associated textures. If you encounter any issues importing your models or need further assistance, please don't hesitate to contact Sunny for help."
      ],
      "metadata": {
        "id": "Gb_cuSvZUzPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Disclaimer on Object Detection in Unity**:\n",
        "Object detection within Unity environments can present unique challenges and may not always yield perfect results on the first try. It's important to understand that achieving accurate detection might require adjustments to your 3D environment, dataset or model parameters. Experimentation and iteration are key components of developing a successful object detection system in Unity. Be prepared to refine your approach based on the results you observe.\n"
      ],
      "metadata": {
        "id": "imiDkP-SUWNq"
      }
    }
  ]
}